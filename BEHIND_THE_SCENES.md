# Behind the Scenes: How a User Question Becomes a Data-Driven Answer

This document traces the complete flow from a user typing a question in the chat to receiving a formatted answer with live data from the database.

## The Example

The user types: *"Which employees are in the Sales department?"*

---

## Step 1: User Types a Question in the UI

The user types their question into the DevExpress chat control — `DxAIChat` on Blazor Server or `AIChatControl` on WinForms. These controls are standard DevExpress AI components that accept an `IChatClient` via dependency injection.

## Step 2: DevExpress Chat Control Calls `IChatClient`

The DevExpress AI controls are wired to `IChatClient` through DI, registered in `ServiceCollectionExtensions.AddCopilotSdk()`. The control calls either `GetResponseAsync` or `GetStreamingResponseAsync` on **`CopilotChatClient`** — the adapter that bridges DevExpress to the Copilot SDK.

The adapter extracts the last user message and forwards it as a plain string:

```
CopilotChatClient.GetStreamingResponseAsync()
  → extracts "Which employees are in the Sales department?"
  → calls _service.AskStreamingAsync(prompt)
```

**Relevant file:** `Module/Services/CopilotChatClient.cs`

## Step 3: `CopilotChatService` Creates a Copilot SDK Session

Inside `CopilotChatService.AskAsync()`, the following happens:

1. **Starts the SDK client** if not already running — `EnsureStartedAsync()` calls `_client.StartAsync()`, which authenticates with GitHub via CLI credentials or a Personal Access Token.

2. **Builds a `SessionConfig`** containing three critical pieces:
   - The AI **model** (e.g. `gpt-4o`, configurable at runtime)
   - The **tools** — the three `AIFunction` objects from `CopilotToolsProvider` (`list_entities`, `query_entity`, `create_entity`)
   - The **system message** — the dynamically generated prompt from `SchemaDiscoveryService` that describes all entities, their properties, relationships, and enum values

3. **Creates a session** with the Copilot SDK: `_client.CreateSessionAsync(config)`

4. **Subscribes to events** — listening for `AssistantMessageDeltaEvent` (response chunks), `SessionIdleEvent` (response complete), and `SessionErrorEvent` (failures)

5. **Sends the user's prompt** via `session.SendAsync()`

**Relevant file:** `Module/Services/CopilotChatService.cs`

## Step 4: The Copilot SDK Sends Everything to the AI Model

The GitHub Copilot SDK packages and sends to the AI model (e.g. GPT-4o):

- The **system message** — generated by `SchemaDiscoveryService.GenerateSystemPrompt()`. This is a Markdown document describing all 13 entities with their properties, data types, relationships, and enum values. It looks like:
  ```
  You are a helpful business assistant for an order management application.
  The database contains these entities:

  - **Category** (Name, Description)
    - has many Product (via Products)
  - **Customer** (CompanyName, ContactName, Phone, ...)
    - has many Order (via Orders)
  - **Department** (Name, Code, Location, Budget, IsActive)
    - has many Employee (via Employees)
  - **Employee** (FirstName, LastName, Title, HireDate, ...)
    - belongs to Department (via Department)
    - has many Order (via Orders)
  ...
  ```

- The **tool definitions** — JSON schemas describing the three available tools with their parameters and descriptions

- The **user's question** — `"Which employees are in the Sales department?"`

**Relevant file:** `Module/Services/SchemaDiscoveryService.cs`

## Step 5: The AI Model Decides to Call a Tool

The AI reads the system prompt, understands the schema, and decides it needs to fetch live data. Based on the user's question, the model returns a **tool call** request:

```json
{
  "name": "query_entity",
  "arguments": {
    "entityName": "Employee",
    "filter": "Department=Sales"
  }
}
```

The AI chose `query_entity` because it understood:
- The user is asking *about* employees (not creating or listing schema)
- The filter should be on the `Department` relationship with value `Sales`
- It knows `Department` is a valid relationship on `Employee` because the system prompt told it so

The **Copilot SDK handles tool execution automatically** — it matches the tool call name to the registered `AIFunction` and invokes it with the provided arguments.

## Step 6: `CopilotToolsProvider.QueryEntity()` Executes

This is where the actual database query happens. The method follows these steps:

### 6a. Find Entity Metadata

```csharp
var entityInfo = _schemaService.Schema.FindEntity("Employee");
```

Returns the `EntityInfo` for Employee — including all its scalar properties (FirstName, LastName, Title, etc.) and relationships (Department, Orders, Territories, DirectReports).

### 6b. Create a Scoped ObjectSpace

```csharp
using var sos = GetObjectSpace(entityType);
```

Creates a DI scope, obtains an `INonSecuredObjectSpaceFactory`, and creates an `IObjectSpace` for the Employee type. This is the standard XAF data access pattern — the ObjectSpace wraps EF Core's DbContext and handles the database connection.

### 6c. Load All Employee Objects

```csharp
var allObjects = os.GetObjects(entityType);
```

Fetches all Employee records from the SQLite database via EF Core. The ObjectSpace handles entity materialization and change tracking.

### 6d. Parse the Filter

```csharp
var filterPairs = ParsePairs("Department=Sales");
// Result: [("Department", "Sales")]
```

Splits the semicolon-separated filter string into key-value pairs.

### 6e. Apply the Filter

The key `"Department"` is not a scalar property on Employee — it's a **to-one navigation property** (a relationship). The code detects this and filters by matching the referenced object's display text:

```csharp
// For each Employee, read the Department navigation property
var refObj = member.GetValue(obj);  // → the Department object
// Get its display text (uses the Name property)
var display = GetObjectDisplayText(refObj);  // → "Sales"
// Check if it matches the filter value (case-insensitive contains)
return display.IndexOf(value, StringComparison.OrdinalIgnoreCase) >= 0;
```

`GetObjectDisplayText()` tries common name properties (`Name`, `CompanyName`, `FullName`, etc.) to produce a human-readable label. For Department, it finds `Name` → `"Sales"`.

### 6f. Format the Results

For each matching Employee, `FormatObject()` builds a pipe-separated string of all scalar properties plus to-one references:

```
Found 2 Employee record(s):
FirstName: Nancy | LastName: Davolio | Title: Sales Manager | HireDate: 2020-01-05 | Email: nancy@example.com | Phone: 555-0100 | Department: Sales
FirstName: Andrew | LastName: Fuller | Title: Senior Sales | HireDate: 2021-03-12 | Email: andrew@example.com | Phone: 555-0101 | Department: Sales
```

This formatted string is returned to the Copilot SDK.

**Relevant file:** `Module/Services/CopilotToolsProvider.cs`

## Step 7: The AI Model Formulates a Human-Friendly Response

The Copilot SDK feeds the tool result back to the AI model. The model now has the raw data and composes a natural language answer, typically with Markdown formatting:

> **Employees in the Sales Department:**
>
> | Name | Title | Hire Date | Email |
> |------|-------|-----------|-------|
> | Nancy Davolio | Sales Manager | 2020-01-05 | nancy@example.com |
> | Andrew Fuller | Senior Sales | 2021-03-12 | andrew@example.com |

The AI decides the presentation format — it might use tables, bullet lists, or prose depending on what fits the question best.

## Step 8: Response Streams Back to the UI

The AI's response arrives via `AssistantMessageDeltaEvent` events, collected in a `StringBuilder`. When the `SessionIdleEvent` fires, the response is complete.

The response flows back up the entire chain:

```
CopilotChatService.AskAsync() returns the full text
  → CopilotChatClient yields it as ChatResponseUpdate
    → DevExpress DxAIChat / AIChatControl renders it
      → Markdown is converted to HTML via CopilotChatDefaults.ConvertMarkdownToHtml()
```

The user sees a nicely formatted answer in the chat window.

---

## Complete Flow Diagram

```
User types question
  │
  ▼
DxAIChat / AIChatControl (DevExpress UI)
  │
  ▼
CopilotChatClient (IChatClient adapter)
  │  extracts last user message as plain text
  ▼
CopilotChatService.AskAsync()
  │  creates session with: model + tools + system prompt
  ▼
GitHub Copilot SDK → AI Model (GPT-4o / Claude / Gemini / etc.)
  │
  │  AI reads system prompt (entity schema)
  │  AI reads user question
  │  AI decides: "I need to call query_entity"
  │
  ▼
Tool call: query_entity("Employee", "Department=Sales")
  │
  ▼
CopilotToolsProvider.QueryEntity()
  │  SchemaDiscoveryService → find entity metadata
  │  IObjectSpace → XAF/EF Core → SQLite database
  │  filter + format results
  │
  ▼
Tool result returned to AI Model
  │
  │  AI composes a formatted answer with the data
  │
  ▼
Response streams back via events
  │
  ▼
CopilotChatClient → ChatResponseUpdate
  │
  ▼
DxAIChat / AIChatControl renders Markdown as HTML
  │
  ▼
User sees the answer
```

## Key Design Decisions

- **The AI model decides which tool to call.** The system prompt gives the AI enough schema knowledge to choose the right tool and construct appropriate filters. The application never hardcodes "if the user asks about employees, query the Employee table."

- **Tools are generic, not entity-specific.** `query_entity` works with any of the 13 entities. There is no `get_employees()` or `get_departments()` method. This is why adding a new entity requires zero changes to the service layer.

- **Filtering by relationship uses display text matching.** When the user says "Sales department", the tool resolves this by reading each Employee's Department object and comparing its display name. This is powered by `GetObjectDisplayText()` which tries common name properties.

- **XAF ObjectSpace handles all data access.** The tools use `INonSecuredObjectSpaceFactory` to create short-lived ObjectSpaces scoped to each tool call. This follows standard XAF patterns and ensures proper EF Core lifecycle management.

- **Schema discovery happens once at startup.** `SchemaDiscoveryService` reflects over `ITypesInfo` on first access and caches the result. The system prompt and tool definitions are built from this cached metadata, so there is no per-request reflection overhead.
